{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a6b67f",
   "metadata": {},
   "source": [
    "복습\n",
    "1. 로지스틱 회귀\n",
    "    - 선형 점수 → 확률로 변환 → 임계값으로 0/1 분류한다.\n",
    "2. knn\n",
    "    - 가까운 k개 이웃의 정답을 투표(또는 비율)해서 분류한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ee733",
   "metadata": {},
   "source": [
    "모델이 질문을 던짐(예/아니오), 계속 분기가 만들어짐.\n",
    "\n",
    "트리구조&트리알고리즘?\\\n",
    "하나의 뿌리에서 여러가지, 마치 나무처럼 확장되는 구조."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d785c5b8",
   "metadata": {},
   "source": [
    "# 분류3: 결정트리(Decision Tree): 질문으로 데이터를 계속 나누는 분류 모델\n",
    "결정트리는 질문(조건)을 하나씩 던져가며 데이터를 나누고, 마지막에 라벨을 결정하는 분류 모델이다.\n",
    "\n",
    "예시:\\\n",
    "꽃잎 길이가 2.5보다 큰가? → 예/아니오로 나눔\\\n",
    "그럼 꽃잎 폭이 1.8보다 큰가? → 다시 나눔\\\n",
    "이렇게 질문을 이어가서 최종 분류를 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb20b5a4",
   "metadata": {},
   "source": [
    "## 트리 구조와 용어(기본)\n",
    "결정트리는 그림으로 보면 **나무**처럼 생겼고, 용어도 그 구조를 그대로 부른다.\n",
    "- 노드(Node): 질문이 있는 점(분기점)\n",
    "- 루트 노드(Root): 트리의 시작점(첫 질문)\n",
    "- 분기(Branch): 질문 결과에 따라 갈라지는 길(예/아니오)\n",
    "- 리프 노드(Leaf): 더 이상 질문하지 않고 최종 예측을 내는 끝점\n",
    "- 깊이(Depth): 질문을 몇 번 거쳐 왔는지(트리가 얼마나 길게 내려갔는지)\n",
    "\n",
    "> 위에서 질문 시작(루트) → 중간에서 계속 나눔(노드/브랜치) → 끝에서 결론(리프)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8466ff",
   "metadata": {},
   "source": [
    "## 결정트리의 \"핵심 질문:은 뭐냐?\n",
    "어떤 기준으로 나누면, 한쪽에 같은 라벨이 더 많이 모일까?\n",
    "\n",
    "즉, 매 단계마다 **이 질문으로 나눴을 때**\\\n",
    "왼쪽 그룹은 0이 더 많아지고\\\n",
    "오른쪽 그룹은 1이 더 많아지는\\\n",
    "**깔끔한 분리**가 되는 질문을 찾는다.\n",
    "\n",
    "이 깔끔함을 보통 **불순도(impurity)**를 줄인다고 표현한다.\n",
    "\n",
    "예시: 합격/불합격 예측\\\n",
    "\n",
    "1. 공부시간 ≥ 3시간?\n",
    "    - 예(≥3): 합격이 많음\n",
    "    - 아니오(<3): 불합격이 많음\n",
    "2. (≥3인 그룹에서) 모의고사 점수 ≥ 70?\n",
    "    - 예: 거의 합격\n",
    "    - 아니오: 합격/불합격 섞임 → 추가 질문 가능\n",
    "\n",
    "이런 식으로 질문이 내려갈수록 그룹이 점점 한 라벨로 모이게 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6288a",
   "metadata": {},
   "source": [
    "## 결정트리의 장단점\n",
    "\n",
    "- 장점\n",
    "    - 해석이 쉽다: 왜 이렇게 예측했는지 질문 경로로 설명 가능\n",
    "    - 전처리 부담이 적다. 스케일링(표준화) 없이도 잘 도는 편\n",
    "    - 비선형 경계도 잘 잡는다. (직선만 고집하지 않음)\n",
    "\n",
    "- 단점\n",
    "    - 과적합이 잘 된다: 질문을 너무 많이 하면 훈련 데이터에만 딱 맞게 외워버림\\\n",
    "    → 그래서 보통 깊이 제한 같은 규제가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86c62d",
   "metadata": {},
   "source": [
    "## max_depth = 깊이 = 질문 횟수 제한 (질문 노드(분기) 수) = 중요\n",
    "결정트리는 데이터를 분류할 때 질문을 연달아 한다.\\\n",
    "max_depth는 그 연속 질문의 최대 횟수를 제한하는 값이다.\n",
    "값을 크게 하면 더 세밀하게 나누고, 너무 크게 하면 훈련 데이터를 외워 과적합이 생기기 쉽다.\n",
    "\n",
    "### 예시\n",
    "\n",
    "1. max_depth = 1 (최대 질문 1번 가능)\\\n",
    "구조: Q1: A > 3인가?\n",
    "예 → 결론 | 아니오 → 결론\\\n",
    "즉, 한 번만 물어보고 바로 결정.\n",
    "\n",
    "2. max_depth = 2 (최대 질문 2번 가능)\\\n",
    "구조: Q1\\\n",
    "예 → Q2 → 결론\\\n",
    "아니오 → Q2 → 결론\\\n",
    "즉, 최대 두 번까지 꼬리 질문 가능.\n",
    "\n",
    "max_depth를 제한하지 않으면?\\\n",
    "데이터가 더 이상 깔끔히 안 나뉠 때까지 계속 질문하면서 훈련 데이터에 딱 맞는 **규칙을 외워버릴 수 있음** → 과적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea995d",
   "metadata": {},
   "source": [
    "## 불순도 - 트리가 \"어떤 질문을 할지\" 결정하는 기준\n",
    "결정트리는 매 단계마다 이런 목표로 질문을 고른다.\\\n",
    "이 질문으로 나누면, 각 그룹이 한 클래스(라벨)로 더 잘 모일까?\\\n",
    "즉, 섞여 있는 정도(불순도)를 가장 많이 줄이는 질문을 골라야 한다.\n",
    "\n",
    "### 불순도란?\n",
    "한 노드(그룹) 안에 라벨이 얼마나 섞여 있는지를 숫자로 나타낸 것.\\\n",
    "한 라벨로 거의 꽉 차 있으면 → 불순도 낮음 (좋음)\\\n",
    "여러 라벨이 비슷하게 섞여 있으면 → 불순도 높음 (나쁨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2d5a97",
   "metadata": {},
   "source": [
    "### 불순도를 재는 대표 기준(분류 트리)\n",
    "- 지니 불순도(Gini): 한 노드에서 라벨이 섞여 있을 확률을 수치로 본다 (sklearn 기본)\n",
    "- 엔트로피(Entropy): 한 노드의 라벨이 얼마나 예측하기 어렵고 정보가 불확실한지를 수치로 본다 (불확실성 측정)\n",
    "\n",
    "결국 두 방법 다 **더 깔끔하게 나뉘는 질문**을 고르는 것이 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a062c3",
   "metadata": {},
   "source": [
    "## 트리가 질문을 고르는 방식\n",
    "각 후보 질문(분할)에 대해 아래를 계산한다.\n",
    "1. 분할 전(부모 노드) 불순도\n",
    "2. 분할 후(왼쪽/오른쪽 자식 노드) 불순도의 가중 평균\n",
    "3. 불순도 감소량 = (분할 전) − (분할 후 가중평균)\n",
    "\n",
    "그리고 불순도 감소량이 가장 큰 질문을 선택한다.\n",
    "\n",
    "> 불순도를 가장 많이 줄이는 질문 = 가장 좋은 질문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a3150",
   "metadata": {},
   "source": [
    "### 간단 예시 (지니로 감 잡기)\n",
    "어떤 노드에 데이터 10개가 있고 라벨이 0/1이 5개씩 있다고 하자.\\\n",
    "→ 섞임이 심하니까 불순도가 높다.\n",
    "\n",
    "Gini 불순도\\\n",
    "부모 노드(5:5) 지니: $1−(0.5^2+0.5^2)=0.5$\n",
    "\n",
    "- 질문 A로 나눴더니\n",
    "    - 왼쪽: (0만 5개) → 지니 0\n",
    "    - 오른쪽: (1만 5개) → 지니 0\n",
    "    - 가중평균 0 → 불순도 감소량 = 0.5 - 0 = 0.5 (엄청 좋음)\n",
    "\n",
    "- 질문 B로 나눴더니\n",
    "    - 왼쪽: (0이 4, 1이 1) → 지니  $1−(0.8^2+0.2^2)=0.32$\n",
    "    - 오른쪽: (0이 1, 1이 4) → 지니 0.32\n",
    "    - 가중평균 0.32 → 불순도 감소량 = 0.5 - 0.32 = 0.18 (A보다 별로)\n",
    "\n",
    "→ 이렇게 되면 트리는 질문 A를 고른다. 더 \"깔끔하게\" 나누기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1db4b0",
   "metadata": {},
   "source": [
    "## 과적합 ㅡ  max_depth = None이면 왜 위험한가?\n",
    "과적합이란?: 모델이 진짜 패턴만 배우는 게 아니라, 훈련 데이터에만 있는 노이즈/우연한 특징까지 외워\\\n",
    "훈련 성능은 높은데, 새로운 데이터(test)에는 성능이 떨어지는 상태다.\n",
    "\n",
    "### 위험한 이유\n",
    "결정트리는 \"질문을 던져 데이터를 나누는 모델\"인데, max_depth=None이면 질문을 멈추지 않고 계속 쪼갤 수 있다.\\그러면 트리가가 데이터가 조금이라도 섞여 있으면 더 쪼개서 결국 거의 한 샘플 단위까지 맞춰버릴 수 있다.\n",
    "\n",
    "즉, 훈련 데이터는 외워 거의 완벽하게 맞추나,\n",
    "그 규칙이 일반적인 규칙이 아니라 훈련 데이터 전용 규칙이 되기 쉬워서 위험하다.\n",
    "\n",
    "때문에 깊이가 제한이 없으면 트리는 계속 분기해서 결정경계가 매우 복잡해진다.\\\n",
    "복잡한 경계는 훈련 데이터의 작은 흔들림(노이즈)까지 따라간다.\n",
    "\n",
    "### 간단예시\n",
    "합격/불합격을 예측한다고 하자\\\n",
    "진짜 중요한 규칙은 \"공부시간이 많고 점수가 높으면 합격\" 같은 큰 흐름일 수 있다.\n",
    "\n",
    "만약 max_depth=None이면....\\\n",
    "트리가 끝없이 쪼개어\\\n",
    "\"공부시간이 3.1이고 점수가 68이면 불합격\"\\\n",
    "\"공부시간이 3.2이고 점수가 68이면 합격\"\\\n",
    "과 같이 훈련 데이터에만 딱 맞는 예외 규칙을 계속 만들어낼 수 있다.\n",
    "\n",
    "훈련에서는 맞지만, 새로운 사람에게는 이런 예외 규칙이 잘 안 맞아서 성능이 떨어진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ff193",
   "metadata": {},
   "source": [
    "디시전 바운더리??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53b4d5",
   "metadata": {},
   "source": [
    "## 가지치기(pruning) - 과적합을 막는 3가지 하이퍼파라미터\n",
    "결정트리는 질문을 계속 늘리면 훈련 데이터를 너무 세밀하게 외워서(과적합) 문제가 생긴다.\\\n",
    "가지치기(pruning)는 트리가 필요 이상으로 복잡해지지 않게 제한해, **일반화 성능(test 성능)**을 올리는 방법이다.\n",
    "\n",
    "### 3가지 도구\n",
    "1) 깊이 제한 — max_depth\\\n",
    "트리가 최대 몇 번까지 질문할 수 있는지 제한한다.\\\n",
    "깊이를 줄이면 경계가 단순해져서 과적합이 줄어든다.\\\n",
    "너무 작으면 과소적합이 될 수 있다.\n",
    "\n",
    "2) 너무 작은 분할 막기 — min_samples_split, min_samples_leaf\\\n",
    "1.min_samples_split: 노드를 나누려면 최소 몇 개 데이터가 있어야 하는가?\\\n",
    "→ 데이터가 너무 적은 곳에서 \"쪼개기\"를 못 하게 막는다\\\n",
    "2.min_samples_leaf: 리프(결론 노드)에 최소 몇 개 데이터가 남아야 하는가\\\n",
    "→ 1~2개 샘플만 맞추는 \"외우기 리프\"가 생기는 걸 방지\\\n",
    "\"샘플이 너무 적으면 분할 금지\" → 과적합 방지\n",
    "\n",
    "3) 비용-복잡도 가지치기 — ccp_alpha (post-pruning)\\\n",
    "트리를 일단 만든 뒤, 복잡한 가지를 잘라내는 방식\\\n",
    "ccp_alpha를 크게 할수록 \"복잡한 트리는 벌점\"을 더 크게 주고, 트리를 더 단순하게 만든다.\\\n",
    "\"정확도 + 단순함\"을 같이 보며 불필요한 가지를 자른다.\n",
    "\n",
    "### 간단예시(감각)\n",
    "훈련 데이터에서 어떤 노드가 6개 샘플로 구성되어 있는데,\\\n",
    "그중 1개가 예외적으로 다른 라벨이라 트리가 그 1개를 맞추려고 또 쪼갠다고 하자.\n",
    "\n",
    "가지치기 없이 시행:\\\n",
    "\"그 1개를 맞추기 위한 질문\"이 추가됨 → 훈련 정확도는 오르지만, 새 데이터에선 잘 안 맞음(과적합)\n",
    "\n",
    "가지치기를 적용:\\\n",
    "max_depth로 더 깊게 못 내려가게 하거나\\\n",
    "min_samples_leaf=3처럼 리프에 최소 샘플을 강제하거나\\\n",
    "ccp_alpha로 \"예외 1개 맞추는 복잡한 가지\"를 잘라냄\\\n",
    "→ 훈련 정확도는 약간 떨어질 수 있지만, test 정확도는 더 좋아질 수 있음\n",
    "\n",
    "정리 한 줄\n",
    "- max_depth: 질문 횟수 제한\n",
    "- min_samples_split/leaf: 소표본 분할 금지(몇개 이상 샘플, 몇개 이상 노드)\n",
    "- ccp_alpha: 복잡한 가지를 벌점으로 잘라내기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3207c",
   "metadata": {},
   "source": [
    "## feature importance(특성 중요도)\n",
    "모델이 예측할 때 어떤 변수(feature)를 더 많이 참고했는지를 숫자로 보여주는 값이다.\n",
    "\n",
    "결정트리에서의 의미:\\\n",
    "결정트리는 질문을 하면서 데이터를 나누는데,\\\n",
    "어떤 변수가 **불순도를 많이 줄이는 좋은 질문**에 자주 쓰이면 그 변수가 중요도가 높아진다.\n",
    "\n",
    "한 줄 예시\\\n",
    "\"꽃잎 길이\"로 나누면 분류가 확 깔끔해지고,\\\n",
    "\"꽃잎 폭\"은 거의 도움이 안 됐다면\\\n",
    "→ 꽃잎 길이 중요도 ↑, 꽃잎 폭 중요도 ↓\n",
    "\n",
    "주의(짧게)\\\n",
    "중요도가 높다고 해서 **원인(인과)**이라는 뜻은 아니다. (그냥 \"예측에 많이 썼다\"는 단서일 뿐이다.)\n",
    "\n",
    "\n",
    "\n",
    "feature importance는 분류 예측을 위해 트리가 데이터를 나눌 때,\\\n",
    "어떤 피처가 분리를 얼마나 많이/잘 도와줬는지(= 불순도를 얼마나 줄였는지)를 점수로 나타낸 거다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f2630",
   "metadata": {},
   "source": [
    "## gridsearchCV - 최적의 하이퍼파라미터 조합 탐색\n",
    "\n",
    "\n",
    "max_depth(깊이)\n",
    "\n",
    "min_samples_split, min_samples_leaf(가지치기)\n",
    "\n",
    "criterion(gini/entropy)\n",
    "\n",
    "GridSearchCV는 아래 과정을 자동으로 반복한다.\n",
    "\n",
    "하이퍼파라미터 후보 조합을 만든다(격자, grid)\n",
    "\n",
    "각 조합마다\n",
    "\n",
    "K-Fold 교차검증으로 훈련/검증을 여러 번 반복\n",
    "\n",
    "성능 점수를 평균내서 “이 조합의 실력”을 추정한다\n",
    "\n",
    "평균 점수가 가장 좋은 조합을 best_params_로 저장한다\n",
    "\n",
    "그 최적 조합으로 학습된 모델을 best_estimator_로 제공한다\n",
    "\n",
    "중요한 점: GridSearchCV는 “튜닝 + 교차검증”이 한 번에 들어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2648b4eb",
   "metadata": {},
   "source": [
    "## 실무팁 - 결측치와 클래스 불균형 처리\n",
    "1. 결측치 처리\n",
    "2. 클래스 불균형 - class_weight = 'balanced'\n",
    "3. pr curve 로 불균형 데이터 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf0514",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀 vs knn vs 결정트리 - 3대 분류기 비교\n",
    "\n",
    "비교를 통한 공부가 중요"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
