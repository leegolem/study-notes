{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1e0038",
   "metadata": {},
   "source": [
    "# chapter. 1 간단복습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f410e0",
   "metadata": {},
   "source": [
    "1. 학습의 종류\n",
    "    - 지도학습: (X, y)가 있다. 회귀/분류가 여기에 속한다.\n",
    "    - 비지도학습: y가 없다. 군집/차원축소가 여기에 속한다.\n",
    "    - 강화학습: 행동과 보상으로 학습한다.\n",
    "\n",
    "2. 문제 유횽\n",
    "    - 회귀: y가 연속값(집값, 온도).\n",
    "    - 분류: y가 범주(스팸/정상, 질병 유무).\n",
    "    - 군집: 정답 없이 비슷한 것끼리 묶는다.\n",
    "\n",
    "3. 용어 복습\n",
    "    - feature(X): 입력 변수들(열들).\n",
    "    - label(y), target variable: 정답.\n",
    "    - estimator: 모델 클래스(예: DecisionTreeClassifier)\n",
    "    - transformer: 전처리 변환기(예: StandardScaler)\n",
    "    - pipeline: 전처리+모델을 한 덩어리로 묶는 흐름\n",
    "    - metric: 성능을 숫자로 평가하는 기준(예: accuracy)\n",
    "\n",
    "4. 머신러닝 전체 흐름\n",
    "    1. 데이터 수집\n",
    "    2. 데이터 전처리(traning/test 분리)\n",
    "    3. 모델 선택 및 학습\n",
    "    4. 예측\n",
    "    5. 평가 및 튜닝\n",
    "    6. 개선\n",
    "\n",
    "5. X는 대문자, y는 소문자로 두는 이유(실전 감각)\\\n",
    "X는 feature가 여러 개라 보통 (행, 열) 형태의 행렬이 된다.\\\n",
    "y는 정답이 보통 1개라 (행,) 형태의 벡터가 된다.\n",
    "\n",
    "6. train과 test로 각각 나누는 이유는?\n",
    "    - 모델이 새로운 데이터에 대해 얼마나 잘 일반화되는지 평가하기 위해서\n",
    "    - 과적합(overfitting)을 방지하기 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4325e",
   "metadata": {},
   "source": [
    "sklean의 장점.\\\n",
    "모델만 바꿔끼면 다 똑같이 돌아감.\\\n",
    "즉, 데이터를 따로 전처리를 해주지 않아도 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a05ff6",
   "metadata": {},
   "source": [
    "# chapter. 2 모델선택\n",
    "- 머신러닝 모델은 데이터 의존적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389f430",
   "metadata": {},
   "source": [
    "## 평가착시\n",
    "같은 데이터로 학습하고 같은 데이터로 평가하면 점수가 과하게 잘 나온다.\\\n",
    "이때 이 점수가 \"성능\"이 아닌 \"암기\"일 수도 있다.\n",
    "\n",
    "### 올바른 평가를 하기 위해선? -> train/test split\n",
    "train: 학습용\\\n",
    "test: 최종 실력 확인용(처음 보는 시험지)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e2fed",
   "metadata": {},
   "source": [
    "## 힌번이 아닌 여러번 나누기 -> 교차검증(K-Fold)\n",
    "train/test split은 한 번 평가라서 결과가 흔들릴 수 있다.\\\n",
    "하지만 교차검증(K-Fold)은 여러 번 나눠서 평균을 내므로 더 안정적이다.\n",
    "\n",
    "### K-Fold?\n",
    "데이터를 K 개의 폴드(fold)로 나누어 k번의 훈련과 평가를 수행해 모델을 평가하는 방법이다.\\\n",
    "각 폴드가 한 번씩 테스트 세트로 사용되고, 나머지 폴드들이 훈련 세트로 사용된다.\\\n",
    "이후 최종 성능은 k번의 평가 결과의 평균으로 계산됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f7765",
   "metadata": {},
   "source": [
    "### K-Fold 결과 해석\n",
    "- mean: 모델의 전반적인 성능 수준 (전반적인 수준)\n",
    "    - 값이 클수록: 평균적으로 성능이 좋다\n",
    "    - 값이 작을수록: 평균적으로 성능이 낮다\n",
    "\n",
    "- std: 폴드에 따라 점수가 얼마나 흔들리는지 (안정성)\n",
    "    - 클수록: 분할에 따라 성능이 크게 달라짐 → 불안정(분할 의존 큼)\n",
    "    - 작을수록: 분할이 바뀌어도 성능이 비슷함 → 안정적\n",
    "\n",
    "- SE: 평균의 불확실성. mean이 얼마나 흔들릴 수 있는지(대략 SE = std / sqrt(K))\n",
    "    - 클수록: 평균 성능 추정이 더 불안함(불확실성 큼)\n",
    "    - 작을수록: 평균 성능 추정이 더 탄탄함(불확실성 낮음)\n",
    "\n",
    "| 통계량        | 무엇을 표현?          | 작을 때 의미     | 클 때 의미      | 보통 “좋다” 기준               |\n",
    "| ---------- | ---------------- | ----------- | ----------- | ------------------------ |\n",
    "| 평균 (mean)  | 전반적인 성능 수준       | 성능이 낮음      | 성능이 높음      | 높을수록 좋음(accuracy, f1 기준) |\n",
    "| 표준편차 (std) | 폴드별 성능 흔들림(불안정성) | 분할에 둔감, 안정적 | 분할에 민감, 불안정 | 낮을수록 좋음                  |\n",
    "| 표준오차 (SE)  | 평균 성능 추정의 불확실성   | 평균 추정이 안정적  | 평균 추정이 불안정  | 낮을수록 좋음                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c88f01",
   "metadata": {},
   "source": [
    "### K-Fold 예시\n",
    "k=5인경우\n",
    "\n",
    "1. 데이터를 5개의 폴드로 나눔\n",
    "2. 5번의 반복 수행\n",
    "   - 각 반복에서 하나의 폴드를 테스트 세트로 사용하고, 나머지 4개의 폴드를 훈련 세트로 사용\n",
    "   - 모델을 훈련 세트로 학습시키고, 테스트 세트로 평가\n",
    "3. 5번의 평가 결과를 평균내어 최종 성능을 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ca8b1",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터와 튜닝\n",
    "파라미터: 모델이 데이터로 학습해서 얻는 값(w, b 등)\\\n",
    "하이퍼파라미터: 사람이 미리 정하는 설정값(max_depth, n_neighbors 등)\n",
    "\n",
    "튜닝은 후보를 정해두고 공정하게 비교해서 좋은 조합을 찾는 과정이다.\\\n",
    "모델의 성능과 일반화 능력에 큰 영향을 미치기 때문에 머신러닝 성능의 중요한 요소중 하나다\n",
    "\n",
    "### 과적합/과소적합\n",
    "max_depth가 너무 크면 과적합(훈련을 외움)\\\n",
    "max_depth가 너무 작으면 과소적합(패턴을 못 배움)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd82e1",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 튜닝\n",
    "하이퍼파라미터의 최적 값을 찾기 위한 과정이다.\\\n",
    "그리드 서치(grid search), 랜덤 서치(random search), 베이지안 최적화(Bayesian optimization) 등 다양한 방법이 있다.\n",
    "\n",
    "### 기억할 요소\n",
    "튜닝은 자동 설계자가 아니다.\\\n",
    "내가 준 후보들 안에서만 교차검증으로 공정 비교해주는 자동 실험기다.\\\n",
    "후보 범위를 엉망으로 잡으면 결과도 엉망이 된다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
