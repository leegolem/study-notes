{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4304cdd",
   "metadata": {},
   "source": [
    "# 0. 오늘 수업의 목표\n",
    "수업이 끝나면 학습자는 아래를 \"말로 설명\"할 수 있어야 한다.\n",
    "\n",
    "- groupy가 뭔지: \"기준으로 묶고(그룹) → 요약값(집계)을 만든다\"\n",
    "- merge가 뭔지: \"두 테이블을 키로 붙여서(조인) 정보 확장한다\"\n",
    "- 문자파열/시간 처리가 왜 필요한지: \"분석 가능한 형태로 통일하고 생 피처를 만든다\"\n",
    "- apply/map의 차이: \"간단 치환(map) vs 행 단위 규칙(apply)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c97d8",
   "metadata": {},
   "source": [
    "# 1) 큰 그림: 원본 로그 → 리포트 테이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c026112",
   "metadata": {},
   "source": [
    "## 1.1) 데이터 분석에서 자주 보는 3단 구조\n",
    "### 1. 원본 로그 (거래 / 주문 단위)\n",
    "- 주문 1건, 결제 1건처럼 ‘사건 기록’이 한 행씩 쌓인 데이터\n",
    "- 행 수가 많고, 값의 형식이 제각각임 (원시 데이터, 데이터가 정리되지 않았다.)\n",
    "- 시스템이 저장한 그대로라 분석 친화적이지 않음 \n",
    "<br> <br>\n",
    "특징\n",
    "- 행 기준: “무슨 일이 있었나”\n",
    "- 값이 들쭉날쭉함 (문자열/숫자 섞임, 표기 흔들림)\n",
    "- 그대로는 리포트(요약표) 만들기 어려움 \n",
    "<br> <br>\n",
    " \n",
    "\n",
    "### 2. 분석용 테이블 (정제 / 통일 / 파생)\n",
    "- 분석이 가능하도록 형식과 타입을 통일한 상태\n",
    "<br> <br>\n",
    "\n",
    "주로 하는 작업 \n",
    "- 날짜 형식 통일 → datetime\n",
    "- 가격/수량 → 숫자\n",
    "- 결제 여부 → True / False\n",
    "- 표기 통일 → 공백 제거, 대소문자 통일\n",
    "- 리포트에 필요한 파생 컬럼 생성 (연_월, 요일, 매출 등) \n",
    "<br> <br>\n",
    "\n",
    "### 3. 요약 테이블 (집계 / 피벗)\n",
    "GroupBy / 피벗으로 만든 최종 결과표\n",
    "- 보고서, 대시보드에 바로 붙여 넣을 수 있는 형태 \n",
    "\n",
    "특징\n",
    "- 행 수는 적고\n",
    "- 의미는 압축되어 있음\n",
    "- \"의사결정용 표\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9525cc",
   "metadata": {},
   "source": [
    "## 1.2) 예시로 보기: 카페 매출 데이터\n",
    "원본 로그 예시 컬럼\n",
    "- date, menu, price, qty, paid, store, channel …\n",
    "\n",
    "이 상태로 바로 집계하면 문제가 발생한다.\n",
    "- \"4,500원\" 같은 문자열 때문에 합계/평균 계산이 깨짐\n",
    "- \"Latte\", \"latte\", \" Latte \"가 서로 다른 메뉴로 집계됨\n",
    "- 날짜가 문자열이면 월별/요일별 분석이 번거로움\n",
    "\n",
    "때문에 먼저 분석용 테이블로 바꿀 필요가 있다.\n",
    "- 정제 / 통일\n",
    "    - date → datetime\n",
    "    - price, qty → 숫자\n",
    "    - paid → True / False\n",
    "    - menu 표기 통일\n",
    "\n",
    "- 파생\n",
    "    - ym (연-월)\n",
    "    - day_name (요일)\n",
    "    - sales (매출)\n",
    "\n",
    "이 단계를 거쳐야 집계 결과가 믿을 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8402d7",
   "metadata": {},
   "source": [
    "# 1.3) 최종 요약표(리포트)가 가져야 할 모습\n",
    "\n",
    "- 월별 매출 추이\n",
    "→ 이번 달 vs 지난 달 비교\n",
    "\n",
    "- 요일별 매출 패턴\n",
    "→ 어떤 요일이 강한지 (운영 / 인력 배치)\n",
    "\n",
    "- 메뉴 TOP / 카테고리별 매출\n",
    "→ 잘 팔리는 메뉴 파악 (메뉴 전략)\n",
    "\n",
    "- 결제 성공률 / 실패율\n",
    "→ 오류, 취소, 실패 비중 점검"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa166bf",
   "metadata": {},
   "source": [
    "# 2. GroupBy(그룹화) 이론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc29ba7f",
   "metadata": {},
   "source": [
    "## 2.1) GroupBy란?\n",
    "GroupBy = “기준 컬럼으로 묶고(그룹) → 각 그룹의 요약값(집계)을 만든다” 이다.\n",
    "\n",
    "원본 로그(주문 1건 = 1행)를 리포트용 요약표로 바꿀 때 가장 많이 쓴다.\n",
    "\n",
    "- 메뉴별 매출 합계: “Americano가 총 얼마 벌었나?”\n",
    "- 매장별 주문 수: “광교점은 주문이 몇 건인가?”\n",
    "- 월별 결제 성공률: “이번 달 결제 실패가 늘었나?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558809f4",
   "metadata": {},
   "source": [
    "### groupby 문법구조\n",
    "```python\n",
    "데이터프레임.groupby(기준)[집계대상].집계함수()\n",
    "```\n",
    "- 원본 데이터프레임을\n",
    "- groupby(기준): 무엇을 기준으로 묶을지 (문자열 컬럼명 또는 컬럼명 리스트가 온다)\n",
    "- [집계대상]: 컬럼을 집계할지\n",
    "- 집계함수(): 어떻게 요약할지(집계 함수) (sum, mean, count, nunique, min, max)\n",
    "\n",
    "\n",
    "#### 가장 많이 쓰이는 패턴 3개\n",
    "##### 단일 기준 + 단일 집계\n",
    "```python\n",
    "df.groupby(\"menu\")[\"sales\"].sum()\n",
    "```\n",
    "- menu 기준으로 묶고\n",
    "- sales를 합계로 요약\n",
    "<br> <br>\n",
    "\n",
    "##### 다중 기준 + 단일 집계\n",
    "```python\n",
    "df.groupby([\"ym\", \"menu\"])[\"sales\"].sum()\n",
    "```\n",
    "- ym, menu 기준으로 묶고\n",
    "- sales를 합계로 요약한다\n",
    "<br> <br>\n",
    "\n",
    "##### 단일/다중 기준 + 여러 집계 (리포트형)\n",
    "```python\n",
    "df.groupby(\"store\").agg(\n",
    "    total_sales=(\"sales\", \"sum\"),\n",
    "    orders=(\"menu\", \"count\"),\n",
    "    paid_rate=(\"paid\", \"mean\")\n",
    ")\n",
    "```\n",
    "- store 기준으로 묶고\n",
    "- 여러 컬럼을 여러 방식으로 요약한다\n",
    "<br> <br>\n",
    "\n",
    "\n",
    "##### 결과 형태까지 포함한 문장 구조\n",
    "```python\n",
    "데이터프레임\n",
    "  .groupby(기준)\n",
    "  .agg(집계정의)\n",
    "  .reset_index()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f659707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 로그\n",
      "        date store       menu  sales   paid       ym\n",
      "0 2026-01-01   광교점  Americano   9000   True  2026-01\n",
      "1 2026-01-01   광교점      Latte   5000   True  2026-01\n",
      "2 2026-01-02   광교점      Latte      0  False  2026-01\n",
      "3 2026-01-03   수원점  Americano   4500   True  2026-01\n",
      "4 2026-01-03   수원점      Mocha      0  False  2026-01\n",
      "\n",
      "메뉴별 매출 합계\n",
      "        menu  sales\n",
      "0  Americano  13500\n",
      "1      Latte   5000\n",
      "2      Mocha      0\n",
      "\n",
      "매장별 주문 수\n",
      "  store  orders\n",
      "0   광교점       3\n",
      "1   수원점       2\n",
      "\n",
      "월별 결제 성공률\n",
      "        ym  paid_rate\n",
      "0  2026-01        0.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 주문(원본 로그) 데이터: \"주문 1건 = 행 1개\"\n",
    "df = pd.DataFrame([\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"menu\": \"Americano\", \"sales\": 9000, \"paid\": True},\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 5000, \"paid\": True},\n",
    "    {\"date\": \"2026-01-02\", \"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 0,    \"paid\": False},\n",
    "    {\"date\": \"2026-01-03\", \"store\": \"수원점\", \"menu\": \"Americano\", \"sales\": 4500, \"paid\": True},\n",
    "    {\"date\": \"2026-01-03\", \"store\": \"수원점\", \"menu\": \"Mocha\",     \"sales\": 0,    \"paid\": False},\n",
    "])\n",
    "\n",
    "# 날짜를 datetime으로 바꾸고(dt), 월(ym) 컬럼 생성 (월별 그룹화용)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "print(\"원본 로그\")\n",
    "print(df)\n",
    "\n",
    "# 메뉴별 매출 합계\n",
    "menu_sales = df.groupby(\"menu\")[\"sales\"].sum().reset_index()\n",
    "print(\"\\n메뉴별 매출 합계\")\n",
    "print(menu_sales)\n",
    "\n",
    "# 매장별 주문 수 (행 개수)\n",
    "store_orders = df.groupby(\"store\")[\"menu\"].count().reset_index(name=\"orders\")\n",
    "print(\"\\n매장별 주문 수\")\n",
    "print(store_orders)\n",
    "\n",
    "# 월별 결제 성공률 (True/False 평균)\n",
    "monthly_paid_rate = df.groupby(\"ym\")[\"paid\"].mean().reset_index(name=\"paid_rate\")\n",
    "print(\"\\n월별 결제 성공률\")\n",
    "print(monthly_paid_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2a52b",
   "metadata": {},
   "source": [
    "## 2.2) GroupBy가 왜 필요할까?\n",
    "원본 데이터 대부분 \"행 단위 사건\"이기 때문에 그대로 보면 흐름이 잘 안 보인다.<br>\n",
    "주문 1건을 봐서는 이번 달 매출이 좋은지 판단할 수 없고, 수백 건을 사람 눈으로 보면 패턴이 안 잡힌다.\n",
    "\n",
    "때문에 GroupBy로 \"요약 단위\"를 바꾼다.\n",
    "- 주문 단위 → 메뉴 단위 / 매장 단위 / 월 단위\n",
    "- 요약 단위로 바꾸면 비교·추세·순위 같은 리포트가 가능해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90f4868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 로그(주문 1건 단위):\n",
      "        date store       menu  sales       ym\n",
      "0 2026-01-01   광교점  Americano   9000  2026-01\n",
      "1 2026-01-01   광교점      Latte   5000  2026-01\n",
      "2 2026-01-02   광교점      Latte   5000  2026-01\n",
      "3 2026-01-03   수원점  Americano   4500  2026-01\n",
      "4 2026-01-03   수원점      Mocha   5500  2026-01\n",
      "\n",
      "메뉴 단위 요약(메뉴별 매출 합계):\n",
      "        menu  total_sales\n",
      "0  Americano        13500\n",
      "1      Latte        10000\n",
      "2      Mocha         5500\n",
      "\n",
      "매장 단위 요약(매장별 매출 합계):\n",
      "  store  total_sales\n",
      "0   광교점        19000\n",
      "1   수원점        10000\n",
      "\n",
      "월 단위 요약(월별 매출 합계):\n",
      "        ym  total_sales\n",
      "0  2026-01        29000\n",
      "\n",
      "메뉴 매출 TOP(정렬로 순위 확인):\n",
      "        menu  total_sales\n",
      "0  Americano        13500\n",
      "1      Latte        10000\n",
      "2      Mocha         5500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"menu\": \"Americano\", \"sales\": 9000},\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-02\", \"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-03\", \"store\": \"수원점\", \"menu\": \"Americano\", \"sales\": 4500},\n",
    "    {\"date\": \"2026-01-03\", \"store\": \"수원점\", \"menu\": \"Mocha\",     \"sales\": 5500},\n",
    "])\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "print(\"원본 로그(주문 1건 단위):\")\n",
    "print(df)\n",
    "\n",
    "menu_report = df.groupby(\"menu\")[\"sales\"].sum().reset_index(name=\"total_sales\")\n",
    "store_report = df.groupby(\"store\")[\"sales\"].sum().reset_index(name=\"total_sales\")\n",
    "month_report = df.groupby(\"ym\")[\"sales\"].sum().reset_index(name=\"total_sales\")\n",
    "\n",
    "print(\"\\n메뉴 단위 요약(메뉴별 매출 합계):\")\n",
    "print(menu_report)\n",
    "\n",
    "print(\"\\n매장 단위 요약(매장별 매출 합계):\")\n",
    "print(store_report)\n",
    "\n",
    "print(\"\\n월 단위 요약(월별 매출 합계):\")\n",
    "print(month_report)\n",
    "\n",
    "top_menu = menu_report.sort_values(\"total_sales\", ascending=False)\n",
    "print(\"\\n메뉴 매출 TOP(정렬로 순위 확인):\")\n",
    "print(top_menu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6493811",
   "metadata": {},
   "source": [
    "## 2.3) 집계 함수(aggregation) 핵심 5종\n",
    "- sum: 총합 (총매출, 총수량)\n",
    "- mean: 평균 (평균 매출, 평균 수량, 성공률)\n",
    "- count: 개수 (주문 건수 = 행 개수)\n",
    "- nunique: 고유값 개수 (고유 메뉴 수, 고유 고객 수)\n",
    "- min / max: 최소/최대 (최소/최대 수량, 최대 매출 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5ee8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용한 집계 함수 출력\n",
      "  store  total_sales    avg_sales  orders  unique_menus  min_qty  max_qty  \\\n",
      "0   광교점        14000  4666.666667       3             2        1        2   \n",
      "1   수원점         4500  2250.000000       2             2        1        1   \n",
      "\n",
      "   paid_rate  \n",
      "0   0.666667  \n",
      "1   0.500000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"store\": \"광교점\", \"menu\": \"Americano\", \"qty\": 2, \"sales\": 9000, \"paid\": True},\n",
    "    {\"store\": \"광교점\", \"menu\": \"Latte\",     \"qty\": 1, \"sales\": 5000, \"paid\": True},\n",
    "    {\"store\": \"광교점\", \"menu\": \"Latte\",     \"qty\": 2, \"sales\": 0,    \"paid\": False},\n",
    "    {\"store\": \"수원점\", \"menu\": \"Americano\", \"qty\": 1, \"sales\": 4500, \"paid\": True},\n",
    "    {\"store\": \"수원점\", \"menu\": \"Mocha\",     \"qty\": 1, \"sales\": 0,    \"paid\": False},\n",
    "])\n",
    "\n",
    "summary = df.groupby(\"store\").agg(\n",
    "    total_sales=(\"sales\", \"sum\"),\n",
    "    avg_sales=(\"sales\", \"mean\"),\n",
    "    orders=(\"menu\", \"count\"),\n",
    "    unique_menus=(\"menu\", \"nunique\"),\n",
    "    min_qty=(\"qty\", \"min\"),\n",
    "    max_qty=(\"qty\", \"max\"),\n",
    "    paid_rate=(\"paid\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "print(\"사용한 집계 함수 출력\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d0ad9",
   "metadata": {},
   "source": [
    "## 2.4) 단일 기준 vs 다중 기준\n",
    "단일 기준 그룹화는 “기준이 1개”라서 표가 단순하고 직관적이다.\n",
    "- 예: menu 기준 → 메뉴별 매출 TOP\n",
    "\n",
    "다중 기준 그룹화는 “기준이 2개 이상”이라서 리포트가 풍부해진다.\n",
    "- 예: ym(월) + day_name(요일) 기준 → 월별-요일별 매출 패턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1fc91d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메뉴 단위 요약 \n",
      "        menu  total_sales\n",
      "0  Americano        13500\n",
      "1      Latte        10000\n",
      "2      Mocha         5500\n",
      "\n",
      " 월-요일 단위 요약 (월별·요일별 매출 합계\n",
      "        ym   day_name  total_sales\n",
      "0  2026-01     Friday         5000\n",
      "1  2026-01   Saturday         5000\n",
      "2  2026-01   Thursday         9000\n",
      "3  2026-01    Tuesday         4500\n",
      "4  2026-01  Wednesday         5500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"date\": \"2026-01-01\", \"menu\": \"Americano\", \"sales\": 9000},\n",
    "    {\"date\": \"2026-01-02\", \"menu\": \"Latte\",     \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-03\", \"menu\": \"Latte\",     \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-06\", \"menu\": \"Americano\", \"sales\": 4500},\n",
    "    {\"date\": \"2026-01-07\", \"menu\": \"Mocha\",     \"sales\": 5500},\n",
    "])\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "df[\"day_name\"] = df[\"date\"].dt.day_name()\n",
    "\n",
    "# 단일기준 그룹화. menu 기준 → 메뉴별 매출 TOP\n",
    "menu_report = df.groupby(\"menu\")[\"sales\"].sum().reset_index(name=\"total_sales\")\n",
    "\n",
    "# 다중기준 그룹화. ym(월) + day_name(요일) 기준 → 월별-요일별 매출 패턴\n",
    "ym_day_report = (\n",
    "    df.groupby([\"ym\", \"day_name\"])[\"sales\"].sum()\n",
    "      .reset_index(name=\"total_sales\")\n",
    ")\n",
    "\n",
    "print(\"메뉴 단위 요약 \")\n",
    "print(menu_report)\n",
    "\n",
    "print(\"\\n 월-요일 단위 요약 (월별·요일별 매출 합계\")\n",
    "print(ym_day_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c25f3",
   "metadata": {},
   "source": [
    "## 2.5) agg()가 중요한 이유\n",
    "실무 리포트는 보통 “한 표에 여러 지표”가 들어간다.<br>\n",
    "sum 하나만 뽑고 끝내면 리포트가 아니라 중간 결과가 된다.\n",
    "\n",
    "agg()는 여러 지표를 한 번에 뽑아서 “리포트 표”를 만들게 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f119d364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본\n",
      "  store       menu  sales   paid\n",
      "0   광교점  Americano   9000   True\n",
      "1   광교점      Latte   5000   True\n",
      "2   광교점      Latte      0  False\n",
      "3   수원점  Americano   4500   True\n",
      "4   수원점      Mocha      0  False\n",
      "\n",
      "매장별 요약\n",
      "  store  total_sales  orders  paid_rate\n",
      "0   광교점        14000       3   0.666667\n",
      "1   수원점         4500       2   0.500000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 데이터(주문 1건 = 1행)\n",
    "df = pd.DataFrame([\n",
    "    {\"store\": \"광교점\", \"menu\": \"Americano\", \"sales\": 9000, \"paid\": True},\n",
    "    {\"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 5000, \"paid\": True},\n",
    "    {\"store\": \"광교점\", \"menu\": \"Latte\",     \"sales\": 0,    \"paid\": False},\n",
    "    {\"store\": \"수원점\", \"menu\": \"Americano\", \"sales\": 4500, \"paid\": True},\n",
    "    {\"store\": \"수원점\", \"menu\": \"Mocha\",     \"sales\": 0,    \"paid\": False},\n",
    "])\n",
    "\n",
    "report = df.groupby(\"store\").agg(\n",
    "    total_sales=(\"sales\", \"sum\"),\n",
    "    orders=(\"menu\", \"count\"),\n",
    "    paid_rate=(\"paid\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "print(\"원본\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "print(\"\\n매장별 요약\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e4ae68",
   "metadata": {},
   "source": [
    "## 2.6) MultiIndex가 뭐고 왜 불편한가?\n",
    "다중 기준 groupby를 하면 결과가 MultiIndex(계층 인덱스)로 나오는 경우가 많다. <br>\n",
    "이 상태는 \"표처럼\" 다루기가 불편해질 수 있다(merge, 저장, 피벗 등). <br>\n",
    "그래서 실무에서는 보통 reset_index()로 인덱스를 컬럼으로 내려서 표 형태로 만든다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "996122e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 다중 기준 groupby 결과 (MultiIndex 상태) ===\n",
      "ym       store\n",
      "2026-01  광교점      14000\n",
      "         수원점       4500\n",
      "Name: sales, dtype: int64\n",
      "\n",
      "=== reset_index() 후 (표 형태로 변환) ===\n",
      "        ym store  total_sales\n",
      "0  2026-01   광교점        14000\n",
      "1  2026-01   수원점         4500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"sales\": 9000},\n",
    "    {\"date\": \"2026-01-01\", \"store\": \"광교점\", \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-03\", \"store\": \"수원점\", \"sales\": 4500},\n",
    "])\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "multi = df.groupby([\"ym\", \"store\"])[\"sales\"].sum()\n",
    "print(\"=== 다중 기준 groupby 결과 (MultiIndex 상태) ===\")\n",
    "print(multi)\n",
    "\n",
    "flat = multi.reset_index(name=\"total_sales\")\n",
    "print(\"\\n=== reset_index() 후 (표 형태로 변환) ===\")\n",
    "print(flat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1861d918",
   "metadata": {},
   "source": [
    "# 3) 피벗(표 형태 변환) 이론: 리포트용 표 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d618b594",
   "metadata": {},
   "source": [
    "## 3.1) 피벗이 필요한 순간\n",
    "피벗은 리포트에서 읽히는 표를 만들기 위한 변환이다.\n",
    "\n",
    "원본 데이터는 대부분 다음 구조를 가진다.\n",
    "- 주문 1건 = 1행 구조\n",
    "- 컬럼: date, menu, store, sales …\n",
    "\n",
    "이 구조는 데이터는 많지만, 패턴을 한눈에 보기 어렵다\n",
    "\n",
    "\n",
    "하지만 리포트에서는 보통 이런 표를 원한다.\n",
    "- 행(Row): 월(예: 2026-01, 2026-02)\n",
    "- 열(Column): 요일(예: Mon, Tue)\n",
    "- 값(Value): 매출 합계\n",
    "\n",
    "이렇게 바꾸면 어느 요일이 강한지, 월별 패턴이 어떻게 바뀌는지가 바로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb5175",
   "metadata": {},
   "source": [
    "### 코드로 보기\n",
    "핵심 흐름은 항상 같다.\n",
    "- GroupBy로 먼저 요약한다 (월 + 요일별 매출 합계)\n",
    "- 그 결과를 피벗으로 표 모양으로 펼친다\n",
    "\n",
    "해당 코드를 보면 역할은 명확하다.\n",
    "- GroupBy는 숫자를 만든다\n",
    "- Pivot은 표 모양을 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "932d0129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 로그\n",
      "        date       ym       day       menu  sales\n",
      "0 2026-01-01  2026-01  Thursday  Americano   9000\n",
      "1 2026-01-02  2026-01    Friday      Latte   5000\n",
      "2 2026-01-03  2026-01  Saturday      Latte   5000\n",
      "3 2026-01-06  2026-01   Tuesday  Americano   4500\n",
      "4 2026-02-03  2026-02   Tuesday      Mocha   5500\n",
      "\n",
      "GroupBy 요약(월+요일별 매출)\n",
      "        ym       day  total_sales\n",
      "0  2026-01    Friday         5000\n",
      "1  2026-01  Saturday         5000\n",
      "2  2026-01  Thursday         9000\n",
      "3  2026-01   Tuesday         4500\n",
      "4  2026-02   Tuesday         5500\n",
      "\n",
      "피벗 결과(월 x 요일)\n",
      "day      Friday  Saturday  Thursday  Tuesday\n",
      "ym                                          \n",
      "2026-01  5000.0    5000.0    9000.0   4500.0\n",
      "2026-02     0.0       0.0       0.0   5500.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 원본 로그 (주문 1건 = 1행)\n",
    "df = pd.DataFrame([\n",
    "    {\"date\": \"2026-01-01\", \"menu\": \"Americano\", \"store\": \"광교점\", \"sales\": 9000},\n",
    "    {\"date\": \"2026-01-02\", \"menu\": \"Latte\",     \"store\": \"광교점\", \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-03\", \"menu\": \"Latte\",     \"store\": \"수원점\", \"sales\": 5000},\n",
    "    {\"date\": \"2026-01-06\", \"menu\": \"Americano\", \"store\": \"광교점\", \"sales\": 4500},\n",
    "    {\"date\": \"2026-02-03\", \"menu\": \"Mocha\",     \"store\": \"수원점\", \"sales\": 5500},\n",
    "])\n",
    "\n",
    "# 날짜 파생 컬럼\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "df[\"day\"] = df[\"date\"].dt.day_name()\n",
    "\n",
    "print(\"원본 로그\")\n",
    "print(df[[\"date\", \"ym\", \"day\", \"menu\", \"sales\"]])\n",
    "\n",
    "# 1단계: GroupBy로 요약\n",
    "summary = (\n",
    "    df.groupby([\"ym\", \"day\"])[\"sales\"].sum()\n",
    "      .reset_index(name=\"total_sales\")\n",
    ")\n",
    "\n",
    "print(\"\\nGroupBy 요약(월+요일별 매출)\")\n",
    "print(summary)\n",
    "\n",
    "# 2단계: Pivot으로 표 형태 변환\n",
    "report = (\n",
    "    summary.pivot(index=\"ym\", columns=\"day\", values=\"total_sales\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "print(\"\\n피벗 결과(월 x 요일)\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d4e6e",
   "metadata": {},
   "source": [
    "## 3.2) 긴 형태(long) → 넓은 형태(wide)\n",
    "피벗을 이해하는 가장 쉬운 관점은 이거다.\n",
    "- 긴 형태(long): 요일이 행에 들어 있다\n",
    "- 넓은 형태(wide): 요일이 열로 펼쳐진다\n",
    "\n",
    "요약하면 \"행에 있던 요일을 열로 펼쳐서 표처럼 만든다\"가 피벗이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82e68ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긴 형태(long)\n",
      "        ym  day   sales\n",
      "0  2026-01  Mon  120000\n",
      "1  2026-01  Tue   90000\n",
      "2  2026-02  Mon  150000\n",
      "3  2026-02  Tue   80000\n",
      "\n",
      "넓은 형태(wide)\n",
      "day         Mon    Tue\n",
      "ym                    \n",
      "2026-01  120000  90000\n",
      "2026-02  150000  80000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "long_df = pd.DataFrame([\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"sales\": 120000},\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Tue\", \"sales\":  90000},\n",
    "    {\"ym\": \"2026-02\", \"day\": \"Mon\", \"sales\": 150000},\n",
    "    {\"ym\": \"2026-02\", \"day\": \"Tue\", \"sales\":  80000},\n",
    "])\n",
    "\n",
    "# 긴 형태(long)\n",
    "print(\"긴 형태(long)\")\n",
    "print(long_df)\n",
    "\n",
    "# 넓은 형태(wide)\n",
    "wide_df = long_df.pivot(\n",
    "    index=\"ym\",\n",
    "    columns=\"day\",\n",
    "    values=\"sales\"\n",
    ").fillna(0)\n",
    "\n",
    "print(\"\\n넓은 형태(wide)\")\n",
    "print(wide_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b346c",
   "metadata": {},
   "source": [
    "### 긴 형태(long)\n",
    "- 기준 정보가 행으로 반복된다\n",
    "- 분석에는 편하지만, 사람이 보기에는 불편하다\n",
    "\n",
    "### 넓은 형태(wide)\n",
    "- 기준 중 하나를 열로 펼친다\n",
    "- 리포트에 바로 쓰기 좋은 형태다\n",
    "\n",
    "이렇게 기억하자\n",
    "- long → 분석용 구조\n",
    "- wide → 리포트용 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b08bdb",
   "metadata": {},
   "source": [
    "## 3.3) pivot vs unstack은 뭐가 다른가?\n",
    "pivot과 unstack은 결과 모양은 비슷하지만 출발점이 다르다.\n",
    "\n",
    "- 둘 다 결과를 넓은 형태(wide) 로 만든다\n",
    "- 즉, 행에 있던 기준을 열로 펼친다\n",
    "\n",
    "사용 가이드\n",
    "- 표를 “설계”하는 느낌이 필요하면 → pivot\n",
    "- GroupBy 결과의 인덱스를 바꿔야하면 → unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bca7bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본(long 형태)\n",
      "        ym  day  sales\n",
      "0  2026-01  Mon    100\n",
      "1  2026-01  Mon     50\n",
      "2  2026-01  Tue     80\n",
      "3  2026-02  Mon    120\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 데이터(일부 조합이 반복되도록 일부러 2행 넣음: 2026-01 + Mon)\n",
    "df = pd.DataFrame([\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"sales\": 100},\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"sales\": 50},   # 같은 조합이 2개라서 pivot이 바로 안 됨\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Tue\", \"sales\": 80},\n",
    "    {\"ym\": \"2026-02\", \"day\": \"Mon\", \"sales\": 120},\n",
    "    # 2026-02의 Tue가 없어서 피벗 후 NaN이 생길 수 있음\n",
    "])\n",
    "\n",
    "print(\"원본(long 형태)\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e994439",
   "metadata": {},
   "source": [
    "### pivot\n",
    "지금 내가 가진 데이터에서 행 / 열 / 값이 뭔지 직접 지정해서 표를 만든다\n",
    "\n",
    "pivot의 전제 조건\n",
    "- 한 칸(index + column 조합)에 값이 1개여야 한다\n",
    "- 값이 여러 개면 pivot은 실패한다\n",
    "\n",
    "사고 흐름\n",
    "- 같은 조합을 먼저 하나의 값으로 만든다\n",
    "- 그 다음, 행/열/값을 명시해서 표를 만든다\n",
    "\n",
    "\n",
    "문장 구조\n",
    "```python\n",
    "데이터프레임.pivot(\n",
    "    index=\"행 기준\",\n",
    "    columns=\"열 기준\",\n",
    "    values=\"값\"\n",
    ")\n",
    "```\n",
    "pivot은 GroupBy 이후 이미 요약이 끝난 데이터에서 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46484f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GroupBy 요약 결과\n",
      "        ym  day  sales\n",
      "0  2026-01  Mon    150\n",
      "1  2026-01  Tue     80\n",
      "2  2026-02  Mon    120\n",
      "\n",
      "pivot 결과\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   NaN\n"
     ]
    }
   ],
   "source": [
    "# 1단계: 먼저 요약 (칸당 값 1개 만들기)\n",
    "summary = (\n",
    "    df.groupby([\"ym\", \"day\"])[\"sales\"]\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(\"\\nGroupBy 요약 결과\")\n",
    "print(summary)\n",
    "\n",
    "# 2단계: pivot으로 표 설계\n",
    "report = summary.pivot(\n",
    "    index=\"ym\",\n",
    "    columns=\"day\",\n",
    "    values=\"sales\"\n",
    ")\n",
    "\n",
    "print(\"\\npivot 결과\")\n",
    "print(report)\n",
    "\n",
    "# 즉, pivot은 표 설계 도구다\n",
    "# \"이걸 행으로, 이걸 열로, 이 값을 채운다\"라고 말하는 방식이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6283c1",
   "metadata": {},
   "source": [
    "### unstack\n",
    "이미 GroupBy 결과로 만들어진 계층 인덱스(MultiIndex) 를 열로 펼친다\n",
    "\n",
    "unstack의 전제 조건\n",
    "- 대상은 GroupBy 결과\n",
    "- 보통 결과가 MultiIndex Series다\n",
    "\n",
    "사고 흐름\n",
    "- GroupBy를 한다\n",
    "- 결과가 MultiIndex가 된다\n",
    "- 인덱스 중 하나를 열로 밀어낸다\n",
    "\n",
    "문장구조\n",
    "```python\n",
    "그룹바이_결과.unstack()\n",
    "\n",
    "# 또는\n",
    "\n",
    "그룹바이_결과.unstack(level=인덱스_레벨)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef8c792b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GroupBy 결과 (MultiIndex)\n",
      "ym       day\n",
      "2026-01  Mon    150\n",
      "         Tue     80\n",
      "2026-02  Mon    120\n",
      "Name: sales, dtype: int64\n",
      "\n",
      "unstack 결과\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   NaN\n"
     ]
    }
   ],
   "source": [
    "# GroupBy 결과 (MultiIndex Series)\n",
    "multi = df.groupby([\"ym\", \"day\"])[\"sales\"].sum()\n",
    "\n",
    "print(\"\\nGroupBy 결과 (MultiIndex)\")\n",
    "print(multi)\n",
    "\n",
    "# unstack으로 인덱스 레벨을 열로 펼침\n",
    "wide = multi.unstack()\n",
    "\n",
    "print(\"\\nunstack 결과\")\n",
    "print(wide)\n",
    "# 즉, unstack은 이미 만들어진 구조를 펼치는 도구다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a44d47",
   "metadata": {},
   "source": [
    "### 같은 결과, 다른 출발점\n",
    "#### pivot\n",
    "- 출발점: 일반 DataFrame\n",
    "- 목적: 리포트 표 설계\n",
    "- 질문 형태:\n",
    "    - 행은 뭐냐?\n",
    "    - 열은 뭐냐?\n",
    "    - 값은 뭐냐?\n",
    "\n",
    "→ 사람 중심, 리포트 중심\n",
    "\n",
    "#### unstack\n",
    "- 출발점: GroupBy 결과(MultiIndex)\n",
    "- 목적: 인덱스 구조 변경\n",
    "- 질문 형태:\n",
    "    - 이 인덱스 레벨을 열로 바꿔라\n",
    "\n",
    "→ 판다스 내부 구조 처리용\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88074171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot 방식\n",
    "summary = df.groupby([\"ym\", \"day\"])[\"sales\"].sum().reset_index()\n",
    "pivot_table = summary.pivot(index=\"ym\", columns=\"day\", values=\"sales\")\n",
    "\n",
    "# unstack 방식\n",
    "multi = df.groupby([\"ym\", \"day\"])[\"sales\"].sum()\n",
    "unstack_table = multi.unstack()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529e9d0",
   "metadata": {},
   "source": [
    "차이점은\n",
    "- pivot: DataFrame → 표\n",
    "- unstack: MultiIndex → 표\n",
    "\n",
    "뿐이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660fa161",
   "metadata": {},
   "source": [
    "## 3.4) 피벗에서 자주 만나는 실수 포인트 2개\n",
    "피벗은 문법보다 전제 조건을 모르면 계속 막힌다.\n",
    "\n",
    "아래 2가지만 이해하면 피벗에서 대부분의 에러를 피할수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f164a62b",
   "metadata": {},
   "source": [
    "### 값이 여러 개라서 피벗이 안 되는 경우\n",
    "pivot은 “한 칸 = 값 1개”를 전제로 한다.\n",
    "- (ym, day) 조합 하나당\n",
    "- 값(sales)은 딱 하나여야 한다.\n",
    "\n",
    "\n",
    "왜 문제가 발생하나?\n",
    "- 주문 1건 = 1행\n",
    "- 같은 월 + 같은 요일 주문이 여러 건 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7919e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"sales\": 100},\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"sales\": 50},   # 같은 조합이 반복\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Tue\", \"sales\": 80},\n",
    "    {\"ym\": \"2026-02\", \"day\": \"Mon\", \"sales\": 120},\n",
    "])\n",
    "\n",
    "# 이 상태에서 바로 pivot을 하면,\n",
    "# 2026-01 + Mon 칸에 100과 50 두 개가 동시에 들어가려 해 충돌 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f6cf3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupBy 요약\n",
      "        ym  day  total_sales\n",
      "0  2026-01  Mon          150\n",
      "1  2026-01  Tue           80\n",
      "2  2026-02  Mon          120\n"
     ]
    }
   ],
   "source": [
    "# 1단계: GroupBy로 먼저 요약한다\n",
    "# (칸당 값 1개 만들기)\n",
    "summary = (\n",
    "    df.groupby([\"ym\", \"day\"])[\"sales\"]\n",
    "      .sum()\n",
    "      .reset_index(name=\"total_sales\")\n",
    ")\n",
    "\n",
    "print(\"GroupBy 요약\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d6a3166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pivot 결과\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   NaN\n"
     ]
    }
   ],
   "source": [
    "# 2단계: 그 다음에 pivot을 한다\n",
    "report = summary.pivot(\n",
    "    index=\"ym\",\n",
    "    columns=\"day\",\n",
    "    values=\"total_sales\"\n",
    ")\n",
    "\n",
    "print(\"\\npivot 결과\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83bc5a",
   "metadata": {},
   "source": [
    "### 빈 칸(NaN)이 생기는 것\n",
    "NaN은 에러가 아니라 \"그 조합의 데이터가 없다\"는 뜻이다.\n",
    "\n",
    "왜 NaN이 생기나?\n",
    "- 행: 월\n",
    "- 열: 요일\n",
    "\n",
    "그런데 현실 데이터에서는, 어떤 월에는 화요일 매출이 아예 없을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "afd562b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ym</th>\n",
       "      <th>day</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01</td>\n",
       "      <td>Mon</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-02</td>\n",
       "      <td>Mon</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ym  day  total_sales\n",
       "0  2026-01  Mon          150\n",
       "1  2026-01  Tue           80\n",
       "2  2026-02  Mon          120"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame([\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Mon\", \"total_sales\": 150},\n",
    "    {\"ym\": \"2026-01\", \"day\": \"Tue\", \"total_sales\": 80},\n",
    "    {\"ym\": \"2026-02\", \"day\": \"Mon\", \"total_sales\": 120},\n",
    "    # 2026-02의 Tue는 없음\n",
    "])\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cada899e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피벗 결과 (NaN 발생)\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   NaN\n"
     ]
    }
   ],
   "source": [
    "report = summary.pivot(\n",
    "    index=\"ym\",\n",
    "    columns=\"day\",\n",
    "    values=\"total_sales\"\n",
    ")\n",
    "\n",
    "print(\"피벗 결과 (NaN 발생)\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49091847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "리포트용 (0으로 채움)\n",
      "day        Mon   Tue\n",
      "ym                  \n",
      "2026-01  150.0  80.0\n",
      "2026-02  120.0   0.0\n"
     ]
    }
   ],
   "source": [
    "report_filled = report.fillna(0)\n",
    "\n",
    "print(\"\\n리포트용 (0으로 채움)\")\n",
    "print(report_filled)\n",
    "\n",
    "# 결측 자체가 의미 있는 경우\n",
    "# 측정 실패 나 데이터 누락 분석인 경우 NaN을 유지한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede344b9",
   "metadata": {},
   "source": [
    "# 4. 문자열 처리 이론(실무형) 확장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f164cf12",
   "metadata": {},
   "source": [
    "## 4.1) 왜 문자열 처리가 필수인가?\n",
    "실무 데이터에서 문자열은 거의 항상 정리되지 않은 상태로 들어온다.\n",
    "\n",
    "문제는 이게 단순히 보기만 지저분한 수준이 아니라는 점이다.\n",
    "\n",
    "- 분석 결과가 틀리게 나오거나\n",
    "- 아예 계산 자체가 불가능해진다.\n",
    "\n",
    "즉, 문자열 처리는 선택이 아닌 전처리의 필수 단계다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb4f117",
   "metadata": {},
   "source": [
    "### 발생하는 문제 1. 같은 값인데 다르게 저장됨 (표기 흔들림)\n",
    "실무 데이터에서는 같은 의미의 값이 여러 형태로 저장되는 경우가 매우 많다.\n",
    "- \" Latte \"\n",
    "- \"latte\"\n",
    "- \"LATTE\"\n",
    "\n",
    "사람 눈에는 전부 같은 메뉴로 보인다. 하지만 컴퓨터 입장에서는 완전히 다른 값이다.\n",
    "\n",
    "떄문에 이 상태에서 GroupBy를 하면\n",
    "- Latte가 하나의 그룹으로 묶이지 않는다\n",
    "- 여러 그룹으로 쪼개진다\n",
    "- 결과적으로 메뉴별 집계가 깨진다\n",
    "\n",
    "이 때문에 데이터는 맞게 들어와 있어도 문자열 정리를 안 했다는 이유만으로 분석 결과가 틀어진다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c92b246",
   "metadata": {},
   "source": [
    "### 발생하는 문제 2. 숫자가 문자열로 섞여 들어옴\n",
    "실무 데이터에서는 숫자처럼 보이지만 실제로는 문자열인 값도 매우 흔하다.\n",
    "- \"4,500원\"\n",
    "- \"5000\"\n",
    "- \"5,000원\"\n",
    "\n",
    "눈으로 보면 전부 가격나  하지만 컴퓨터는 이렇게 인식한다.\n",
    "- 쉼표가 들어가 있음\n",
    "- 통화 기호가 붙어 있음\n",
    "\n",
    "이렇게 숫자가 아닌 문자열로 인식하기 때문에 계산이나 집께를 할 수가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b47600",
   "metadata": {},
   "source": [
    "### 발생하는 문제 정리\n",
    "문자열 전처리를 하지 않으면 리포트에서 다음과 같은 문제가 발생한다.\n",
    "\n",
    "- 메뉴별 매출 TOP이 잘못 나온다 (같은 메뉴가 여러 행으로 분리됨)\n",
    "\n",
    "- 가격 합계나 평균이 맞지 않는다 (문자열이라 계산이 안 되거나 일부만 변환됨)\n",
    "\n",
    "- 필터 조건이 제대로 걸리지 않는다 (공백, 대소문자 차이 때문에 조건 누락)\n",
    "\n",
    "이런 문제들은 코드가 틀려서가 아닌 데이터 상태가 분석 불가능했기 때문이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c684ef5",
   "metadata": {},
   "source": [
    "## 4.2) 초보자 기준 핵심 5가지 + 예시코드\n",
    "문자열 처리는 꾸미기 작업이 아니다.\n",
    "- 같은 의미의 값은 같게 만들고\n",
    "- 계산할 값은 숫자로 바꾸는 작업이다\n",
    "\n",
    "즉, 문자열 처리의 목적은 분석 전에 데이터를 분석 가능한 상태로 만드는 것이다.\n",
    "\n",
    "\n",
    "코드를 보며 직접 문제를 해결해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98cb638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터\n",
      "            menu   price           note\n",
      "0         Latte   4,500원     NEW member\n",
      "1          latte    5000     vip MEMBER\n",
      "2          LATTE  5,000원  Member coupon\n",
      "3      Americano   4500원          guest\n",
      "4  Vanilla Latte  5,800원     new_member\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"menu\": \" Latte \",        \"price\": \"4,500원\", \"note\": \"NEW member\"},\n",
    "    {\"menu\": \"latte\",          \"price\": \"5000\",     \"note\": \"vip MEMBER\"},\n",
    "    {\"menu\": \"LATTE\",          \"price\": \"5,000원\",  \"note\": \"Member coupon\"},\n",
    "    {\"menu\": \"Americano\",      \"price\": \"4500원\",   \"note\": \"guest\"},\n",
    "    {\"menu\": \"Vanilla Latte\",  \"price\": \"5,800원\",  \"note\": \"new_member\"},\n",
    "])\n",
    "\n",
    "print(\"원본 데이터\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143fc24",
   "metadata": {},
   "source": [
    "### 공백 제거\n",
    "공백이 사라지면 같은 값인지 비교할 수 있는 상태가 된다.\n",
    "```python\n",
    "공백을_삭제할_값.strip()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "550eb6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "strip 적용 결과\n",
      "            menu     menu_clean\n",
      "0         Latte           Latte\n",
      "1          latte          latte\n",
      "2          LATTE          LATTE\n",
      "3      Americano      Americano\n",
      "4  Vanilla Latte  Vanilla Latte\n"
     ]
    }
   ],
   "source": [
    "df[\"menu_clean\"] = df[\"menu\"].str.strip()\n",
    "\n",
    "print(\"\\nstrip 적용 결과\")\n",
    "print(df[[\"menu\", \"menu_clean\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d890a87",
   "metadata": {},
   "source": [
    "### 대소문자 통일: lower / title\n",
    "\n",
    "문자열 비교에서 대소문자 차이는 다른 값이다.\n",
    "그래서 기준을 하나로 정해야 한다.\n",
    "\n",
    "- title(): 출력용, 리포트에서 보기 좋게 만들 때 사용\n",
    "\n",
    "```python\n",
    "바꿀값.title()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd905915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lower / title 적용 결과\n",
      "      menu_clean     menu_lower     menu_title\n",
      "0          Latte          latte          Latte\n",
      "1          latte          latte          Latte\n",
      "2          LATTE          latte          Latte\n",
      "3      Americano      americano      Americano\n",
      "4  Vanilla Latte  vanilla latte  Vanilla Latte\n"
     ]
    }
   ],
   "source": [
    "df[\"menu_lower\"] = df[\"menu_clean\"].str.lower()\n",
    "df[\"menu_title\"] = df[\"menu_clean\"].str.title()\n",
    "\n",
    "print(\"\\nlower / title 적용 결과\")\n",
    "print(df[[\"menu_clean\", \"menu_lower\", \"menu_title\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e7bb6",
   "metadata": {},
   "source": [
    "### 포함 여부 필터: contains\n",
    "\n",
    "문자열 컬럼에서 특정 단어가 들어간 행만 뽑고 싶을 때 사용한다.\n",
    "\n",
    "- case=False: 대소문자 무시\n",
    "- na=False: 결측값 때문에 에러 나는 것 방지\n",
    "\n",
    "```python\n",
    ".contains()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "845810f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "contains로 member 관련 행만 필터\n",
      "            note\n",
      "0     NEW member\n",
      "1     vip MEMBER\n",
      "2  Member coupon\n",
      "4     new_member\n"
     ]
    }
   ],
   "source": [
    "member_df = df[df[\"note\"].str.contains(\"member\", case=False, na=False)]\n",
    "\n",
    "print(\"\\ncontains로 member 관련 행만 필터\")\n",
    "print(member_df[[\"note\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a45b727",
   "metadata": {},
   "source": [
    "### 치환: replace (문자열 → 숫자 전환의 핵심)\n",
    "가격 데이터는 대부분 문자열로 들어온다. 쉼표, 단위, 기호가 붙어 있기 때문이다.\n",
    "\n",
    "때문에 다음 과정을 거쳐야 한다.\n",
    "1. 문자열에서 불필요한 문자 제거\n",
    "2. 숫자로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8d41ce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "replace + 숫자 변환 결과\n",
      "    price  price_num\n",
      "0  4,500원       4500\n",
      "1    5000       5000\n",
      "2  5,000원       5000\n",
      "3   4500원       4500\n",
      "4  5,800원       5800\n"
     ]
    }
   ],
   "source": [
    "df[\"price_num\"] = (\n",
    "    df[\"price\"]\n",
    "      .str.replace(\",\", \"\", regex=False)\n",
    "      .str.replace(\"원\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "df[\"price_num\"] = pd.to_numeric(df[\"price_num\"], errors=\"coerce\")\n",
    "\n",
    "print(\"\\nreplace + 숫자 변환 결과\")\n",
    "print(df[[\"price\", \"price_num\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5279f3",
   "metadata": {},
   "source": [
    "### 분리: split\n",
    "문자열 하나에 정보가 여러 개 섞여 있을 때 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6679679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "split 적용 결과 (첫 단어 추출)\n",
      "      menu_title menu_first_word\n",
      "0          Latte           Latte\n",
      "1          Latte           Latte\n",
      "2          Latte           Latte\n",
      "3      Americano       Americano\n",
      "4  Vanilla Latte         Vanilla\n"
     ]
    }
   ],
   "source": [
    "df[\"menu_first_word\"] = df[\"menu_title\"].str.split().str[0]\n",
    "\n",
    "print(\"\\nsplit 적용 결과 (첫 단어 추출)\")\n",
    "print(df[[\"menu_title\", \"menu_first_word\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f53b596",
   "metadata": {},
   "source": [
    "# 5. 시간 데이터 처리 이론(실무형)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d7d2f",
   "metadata": {},
   "source": [
    "## 5.1) 왜 날짜 처리가 중요한가?\n",
    "- 월별 매출\n",
    "- 주간 매출\n",
    "- 요일별 패턴\n",
    "- 시간대별 피크 분석\n",
    "\n",
    "이 분석들의 공통점은  전부 시간 데이터를 기준으로 집계한다는 점이다.\n",
    "\n",
    "pandas는 시간 데이터 처리하기 위한 전제조건은 날짜가 문자열(str)이 아니라 datetime 타입이어야 하는 점이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0b7653a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_str</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026/01/02</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026/01/10</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026/01/03</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_str  sales\n",
       "0  2026/01/02    100\n",
       "1  2026/01/10    200\n",
       "2  2026/01/03    150"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"date_str\": [\"2026/01/02\", \"2026/01/10\", \"2026/01/03\"],\n",
    "    \"sales\": [100, 200, 150]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032284e9",
   "metadata": {},
   "source": [
    "### 문제 1. 문자열 날짜는 정렬이 깨진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbd3ac08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자열 기준 정렬\n",
      "     date_str  sales\n",
      "0  2026/01/02    100\n",
      "2  2026/01/03    150\n",
      "1  2026/01/10    200\n",
      "\n",
      "datetime 기준 정렬\n",
      "     date_str  sales       date\n",
      "0  2026/01/02    100 2026-01-02\n",
      "2  2026/01/03    150 2026-01-03\n",
      "1  2026/01/10    200 2026-01-10\n"
     ]
    }
   ],
   "source": [
    "print(\"문자열 기준 정렬\")\n",
    "print(df.sort_values(\"date_str\"))  # 문자열 기준 정렬\n",
    "\n",
    "print(\"\\ndatetime 기준 정렬\")\n",
    "df[\"date\"] = pd.to_datetime(df[\"date_str\"])\n",
    "print(df.sort_values(\"date\"))      # datetime 기준 정렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c0ba5",
   "metadata": {},
   "source": [
    "이런식으로 문자열 상태에서는 01/10이 01/03보다 먼저 올 수도 있다\n",
    "\n",
    "datetime으로 바꾸면 실제 시간 순서대로 정확히 정렬된다.\n",
    "\n",
    "특히나 dd/mm/yyyy 같은 형식은 문자열 정렬과 시간 순서가 더 자주 어긋난다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abf156",
   "metadata": {},
   "source": [
    "### 문제 2. 파생 피처를 만들 수 없다\n",
    "문자열 날짜 상태에서는 시간 분석의 절반 이상을 할 수 없다.\n",
    "\n",
    "대표적인 파생 피처는 다음과 같다.\n",
    "- 연도(year)\n",
    "- 월(month)\n",
    "- 요일(day_name)\n",
    "- 주차(week)\n",
    "- 연-월(ym)\n",
    "\n",
    "이때 만약 날짜가 문자열이면\n",
    "- pandas의 .dt 기능을 쓸 수 없다\n",
    "- month, day_name 같은 파생 컬럼을 만들 수 없다\n",
    "- 월별/요일별 분석이 막힌다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f84c0a0",
   "metadata": {},
   "source": [
    "### 문제 3. 기간 필터링이 어렵다\n",
    "datetime으로 바꾸지 않으면 기간 필터링은 항상 불안정하다.\n",
    "\n",
    "실무에서는 이런 요구가 매우 흔하다.\n",
    "- \"2026년 1월만 보기\"\n",
    "- \"특정 기간만 잘라서 분석하기\"\n",
    "- \"이번 달 vs 지난 달 비교\"\n",
    "\n",
    "이 작업들은 전부 날짜 계산 기반이다.\n",
    "\n",
    "문자열 상태에서는\n",
    "- 포함/제외 경계값 실수가 늘어나고 조건이 복잡해지고 결과를 신뢰하기 어려워진다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356665a",
   "metadata": {},
   "source": [
    "## 5.2) 핵심 개념: \"datetime으로 바꾸고 파생 피처 만든다\"\n",
    "초보자 기준으로 시간 데이터 처리의 핵심은 이 한 줄로 요약된다.\n",
    "\n",
    "- 문자열 날짜 → pd.to_datetime()으로 변환\n",
    "- .dt로 파생 피처 생성\n",
    "- 리포트용으로 연-월(ym) 같은 기준 컬럼을 만든다 <br> <br>\n",
    "\n",
    "문장 구조\n",
    "```python\n",
    "datetime_타입_Series.dt.속성\n",
    "\n",
    "#또는\n",
    "\n",
    "datetime_타입_Series.dt.메소드()\n",
    "``` \n",
    "- 주의사항\n",
    "    - 반드시 Series여야 한다\n",
    "- 속성엔 다음과 같은 값이 들어올수 있다.\n",
    "    - year\n",
    "    - month\n",
    "    - day\n",
    "    - hour 등...\n",
    "- 메소드엔 다음과 같은 키워드가 들어갈수 있다.\n",
    "    - .to_period(\"M\") → 월 단위 기간으로 변환 \n",
    "    - .floor(\"D\") → 날짜를 하루 단위로 내림 (시간 제거, 00:00:00으로 맞춤)\n",
    "    - .strftime(\"%Y-%m\") → 날짜를 \"2026-01\" 같은 문자열 형식으로 변환\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "004ef94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"date\": [\"2026-01-01\", \"2026-01-03\", \"2026-02-01\"],\n",
    "    \"sales\": [10000, 15000, 20000]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b022b462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  sales  year  month  day_name       ym\n",
      "0 2026-01-01  10000  2026      1  Thursday  2026-01\n",
      "1 2026-01-03  15000  2026      1  Saturday  2026-01\n",
      "2 2026-02-01  20000  2026      2    Sunday  2026-02\n"
     ]
    }
   ],
   "source": [
    "# 1) datetime 변환\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# 2) 파생 피처 생성\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"day_name\"] = df[\"date\"].dt.day_name()\n",
    "\n",
    "# 3) 리포트용 연-월 키\n",
    "df[\"ym\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643343e",
   "metadata": {},
   "source": [
    "# 6) 데이터의 결합 (merge / join / concat)\n",
    "\n",
    "###### merge와 join은 같은 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ea57b",
   "metadata": {},
   "source": [
    "## 6.1) 결합은 왜 필요한가?\n",
    "실무에서 사용하는 원본 로그에는 분석에 필요한 정보가 한 테이블에 다 들어있는 경우가 거의 없다.\n",
    "\n",
    "때문에 분석하기 전에 다른 테이블의 정보를 옆으로 붙여서 분석 가능한 형태로 확장한다.\n",
    "\n",
    "\n",
    "예시: 카페 데이터\n",
    "- 주문 로그 테이블\n",
    "    - date, menu, sales, customer_id 는 있음\n",
    "- 메뉴 정보 테이블\n",
    "    - menu → category(커피 / 디저트 등)\n",
    "- 고객 정보 테이블\n",
    "    - customer_id → city, grade\n",
    "\n",
    "주문 데이터만으로는\n",
    "- 카테고리별 매출\n",
    "- 지역별 매출\n",
    "- VIP 고객 매출\n",
    "\n",
    "이런식의 분석이 불가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "923c00b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주문 로그 데이터\n",
      "   order_id        date       menu  sales customer_id\n",
      "0         1  2026-01-01      Latte   5000         C01\n",
      "1         2  2026-01-01  Americano   4500         C02\n",
      "2         3  2026-01-02       Cake   6000         C03\n",
      "\n",
      " 메뉴 정보 데이터\n",
      "        menu category\n",
      "0      Latte   Coffee\n",
      "1  Americano   Coffee\n",
      "\n",
      " 고객 정보 데이터\n",
      "  customer_id    city   grade\n",
      "0         C01   Suwon     VIP\n",
      "1         C02  Yongin     NEW\n",
      "2         C03   Suwon  NORMAL\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orders = pd.DataFrame([\n",
    "    {\"order_id\": 1, \"date\": \"2026-01-01\", \"menu\": \"Latte\",     \"sales\": 5000, \"customer_id\": \"C01\"},\n",
    "    {\"order_id\": 2, \"date\": \"2026-01-01\", \"menu\": \"Americano\", \"sales\": 4500, \"customer_id\": \"C02\"},\n",
    "    {\"order_id\": 3, \"date\": \"2026-01-02\", \"menu\": \"Cake\",      \"sales\": 6000, \"customer_id\": \"C03\"},\n",
    "])\n",
    "\n",
    "menu_map = pd.DataFrame([\n",
    "    {\"menu\": \"Latte\",     \"category\": \"Coffee\"},\n",
    "    {\"menu\": \"Americano\", \"category\": \"Coffee\"},\n",
    "    # Cake는 매핑 누락 상태\n",
    "])\n",
    "\n",
    "customers = pd.DataFrame([\n",
    "    {\"customer_id\": \"C01\", \"city\": \"Suwon\",  \"grade\": \"VIP\"},\n",
    "    {\"customer_id\": \"C02\", \"city\": \"Yongin\", \"grade\": \"NEW\"},\n",
    "    {\"customer_id\": \"C03\", \"city\": \"Suwon\",  \"grade\": \"NORMAL\"},\n",
    "])\n",
    "print(\"주문 로그 데이터\")\n",
    "print(orders)\n",
    "\n",
    "print(\"\\n 메뉴 정보 데이터\")\n",
    "print(menu_map)\n",
    "\n",
    "print(\"\\n 고객 정보 데이터\")\n",
    "print(customers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b337da03",
   "metadata": {},
   "source": [
    "## 6.2) merge = \"키로 붙이는 조인\"\n",
    "merge는 pandas에서 가장 많이 쓰는 결합 방식이다.\n",
    "- 공통 키(key)를 기준으로 두 테이블을 옆으로 붙인다\n",
    "\n",
    "```python\n",
    "왼쪽_데이터프레임.merge(\n",
    "    오른쪽_데이터프레임,\n",
    "    on=\"공통_키\",\n",
    "    how=\"결합_방식\")\n",
    "```\n",
    "- 기준은 항상 왼쪽 데이터프레임\n",
    "- 오른쪽에서 정보를 가져와 붙인다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "230fe835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id        date       menu  sales customer_id category\n",
      "0         1  2026-01-01      Latte   5000         C01   Coffee\n",
      "1         2  2026-01-01  Americano   4500         C02   Coffee\n",
      "2         3  2026-01-02       Cake   6000         C03      NaN\n"
     ]
    }
   ],
   "source": [
    "merged = orders.merge(\n",
    "    menu_map,\n",
    "    on=\"menu\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b29b665",
   "metadata": {},
   "source": [
    "orders를 기준으로\n",
    "- menu를 키로\n",
    "- menu_map의 category를 붙인다\n",
    "\n",
    "merge의 결과로\n",
    "- orders에는 없던 category 컬럼이 생긴다\n",
    "- Cake처럼 매핑이 없는 값은 결측값이 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703073ce",
   "metadata": {},
   "source": [
    "### 결합 이후 분석이 달라진다\n",
    "결합 전엔 메뉴별 매출까지만 가능했으나, <br>\n",
    "결합 후엔 카테고리별 매출로 확장 가능해 졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a9a11cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Coffee    9500\n",
      "Name: sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cat_sales = merged.groupby(\"category\")[\"sales\"].sum()\n",
    "\n",
    "print(cat_sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c413eb3a",
   "metadata": {},
   "source": [
    "## 6.3) how 옵션 (초보자 필수 3종)\n",
    "how는 결합 후에 어떤 행(row)을 남길지 결정하는 옵션이다.\n",
    "\n",
    "how = “기준을 어디에 두고 행을 남길 것인가”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f071d9",
   "metadata": {},
   "source": [
    "### left — 왼쪽(원본) 유지 [LEFT JOIN]\n",
    "\n",
    "```python\n",
    "왼쪽.merge(오른쪽, on=키, how=\"left\")\n",
    "\n",
    "```\n",
    "- 왼쪽 데이터프레임의 행은 전부 유지\n",
    "- 오른쪽에 매핑이 없으면 NaN\n",
    "\n",
    "언제 사용하나?\n",
    "- 실무에서 가장 많이 쓰는 옵션\n",
    "- 원본 로그는 보존하고\n",
    "- 매핑 누락을 NaN으로 확인할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e065925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주문 로그 데이터\n",
      "   order_id        date       menu  sales customer_id\n",
      "0         1  2026-01-01      Latte   5000         C01\n",
      "1         2  2026-01-01  Americano   4500         C02\n",
      "2         3  2026-01-02       Cake   6000         C03\n",
      "\n",
      " 메뉴 정보 데이터\n",
      "        menu category\n",
      "0      Latte   Coffee\n",
      "1  Americano   Coffee\n",
      "\n",
      " 주문 로그+ 메뉴 정보 데이터 (LEFT)\n",
      "   order_id        date       menu  sales customer_id category\n",
      "0         1  2026-01-01      Latte   5000         C01   Coffee\n",
      "1         2  2026-01-01  Americano   4500         C02   Coffee\n",
      "2         3  2026-01-02       Cake   6000         C03      NaN\n"
     ]
    }
   ],
   "source": [
    "left_join = orders.merge(menu_map, on=\"menu\", how=\"left\")\n",
    "\n",
    "print(\"주문 로그 데이터\")\n",
    "print(orders)\n",
    "\n",
    "print(\"\\n 메뉴 정보 데이터\")\n",
    "print(menu_map)\n",
    "\n",
    "print(\"\\n 주문 로그+ 메뉴 정보 데이터 (LEFT)\")\n",
    "print(left_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c031f05",
   "metadata": {},
   "source": [
    "### inner — 양쪽에 모두 있는 것만 [INNER JOIN]\n",
    "```python\n",
    "왼쪽.merge(오른쪽, on=키, how=\"inner\")\n",
    "```\n",
    "- 양쪽 테이블에 공통으로 존재하는 키만 남김\n",
    "- 매핑 안 되는 행은 아예 제거됨\n",
    "\n",
    "언제 사용하나?\n",
    "- 매핑이 제대로 됐는지\n",
    "- 정합성 확인할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b58ce3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주문 로그 데이터\n",
      "   order_id        date       menu  sales customer_id\n",
      "0         1  2026-01-01      Latte   5000         C01\n",
      "1         2  2026-01-01  Americano   4500         C02\n",
      "2         3  2026-01-02       Cake   6000         C03\n",
      "\n",
      " 메뉴 정보 데이터\n",
      "        menu category\n",
      "0      Latte   Coffee\n",
      "1  Americano   Coffee\n",
      "\n",
      " 주문 로그+ 메뉴 정보 데이터 (INNER)\n",
      "   order_id        date       menu  sales customer_id category\n",
      "0         1  2026-01-01      Latte   5000         C01   Coffee\n",
      "1         2  2026-01-01  Americano   4500         C02   Coffee\n"
     ]
    }
   ],
   "source": [
    "inner_join = orders.merge(menu_map, on=\"menu\", how=\"inner\")\n",
    "\n",
    "print(\"주문 로그 데이터\")\n",
    "print(orders)\n",
    "\n",
    "print(\"\\n 메뉴 정보 데이터\")\n",
    "print(menu_map)\n",
    "\n",
    "print(\"\\n 주문 로그+ 메뉴 정보 데이터 (INNER)\")\n",
    "print(inner_join)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498f25a",
   "metadata": {},
   "source": [
    "### outer — 전체 합치기\n",
    "```python\n",
    "왼쪽.merge(오른쪽, on=키, how=\"outer\")\n",
    "```\n",
    "- 양쪽 테이블의 모든 행을 전부 유지\n",
    "- 한쪽에만 있으면 NaN\n",
    "\n",
    "언제 사용하나?\n",
    "- 어느 쪽에만 있는 값이 있는지\n",
    "- 누락 / 신규 항목 탐색할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5f0d3744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주문 로그 데이터\n",
      "   order_id        date       menu  sales customer_id\n",
      "0         1  2026-01-01      Latte   5000         C01\n",
      "1         2  2026-01-01  Americano   4500         C02\n",
      "2         3  2026-01-02       Cake   6000         C03\n",
      "\n",
      " 메뉴 정보 데이터\n",
      "        menu category\n",
      "0      Latte   Coffee\n",
      "1  Americano   Coffee\n",
      "\n",
      " 주문 로그+ 메뉴 정보 데이터 (outer)\n",
      "   order_id        date       menu  sales customer_id category\n",
      "0         2  2026-01-01  Americano   4500         C02   Coffee\n",
      "1         3  2026-01-02       Cake   6000         C03      NaN\n",
      "2         1  2026-01-01      Latte   5000         C01   Coffee\n"
     ]
    }
   ],
   "source": [
    "outer_join = orders.merge(menu_map, on=\"menu\", how=\"outer\")\n",
    "\n",
    "print(\"주문 로그 데이터\")\n",
    "print(orders)\n",
    "\n",
    "print(\"\\n 메뉴 정보 데이터\")\n",
    "print(menu_map)\n",
    "\n",
    "print(\"\\n 주문 로그+ 메뉴 정보 데이터 (outer)\")\n",
    "print(outer_join)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80d5e8",
   "metadata": {},
   "source": [
    "### how 옵션 한눈에 보기\n",
    "\n",
    "left\n",
    "- 왼쪽(원본) 데이터의 행을 전부 유지,<br>매핑이 없으면 NaN으로 표시\n",
    "- 원본 로그 유지 + 매핑 누락 확인할 때 사용\n",
    "\n",
    "<br>\n",
    "\n",
    "inner\n",
    "- 양쪽 테이블에 모두 있는 키만 남김,<br>매핑 안 된 행은 제거됨\n",
    "- 매핑 정합성 확인용으로 사용\n",
    "\n",
    "<br>\n",
    "\n",
    "outer\n",
    "- 양쪽 테이블의 모든 행을 전부 유지,<br>한쪽에만 있으면 NaN 발생\n",
    "- 누락 데이터나 신규 항목 탐색할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31d55e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  (left)\n",
      "left\n",
      "    order_id        date       menu  sales customer_id category\n",
      "0         1  2026-01-01      Latte   5000         C01   Coffee\n",
      "1         2  2026-01-01  Americano   4500         C02   Coffee\n",
      "2         3  2026-01-02       Cake   6000         C03      NaN\n",
      "\n",
      "  (inner)\n",
      "inner\n",
      "    order_id        date       menu  sales customer_id category\n",
      "0         1  2026-01-01      Latte   5000         C01   Coffee\n",
      "1         2  2026-01-01  Americano   4500         C02   Coffee\n",
      "\n",
      "  (outer)\n",
      "outer\n",
      "    order_id        date       menu  sales customer_id category\n",
      "0         2  2026-01-01  Americano   4500         C02   Coffee\n",
      "1         3  2026-01-02       Cake   6000         C03      NaN\n",
      "2         1  2026-01-01      Latte   5000         C01   Coffee\n"
     ]
    }
   ],
   "source": [
    "left_join  = orders.merge(menu_map, on=\"menu\", how=\"left\")\n",
    "inner_join = orders.merge(menu_map, on=\"menu\", how=\"inner\")\n",
    "outer_join = orders.merge(menu_map, on=\"menu\", how=\"outer\")\n",
    "\n",
    "print(\"\\n  (left)\")\n",
    "print(\"left\\n\", left_join)\n",
    "\n",
    "print(\"\\n  (inner)\")\n",
    "print(\"inner\\n\", inner_join)\n",
    "\n",
    "print(\"\\n  (outer)\")\n",
    "print(\"outer\\n\", outer_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf80a5",
   "metadata": {},
   "source": [
    "### 실무 팁: 매핑 누락 찾기 (indicator)\n",
    "매핑표를 붙일 때의 정석 흐름은 이렇다.\n",
    "- left로 붙인다\n",
    "- NaN이 생긴 행을 확인한다\n",
    "- 매핑표를 고친다\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04747e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   menu  order_id\n",
      "2  Cake         3\n"
     ]
    }
   ],
   "source": [
    "check = orders.merge(\n",
    "    menu_map,\n",
    "    on=\"menu\",\n",
    "    how=\"left\",\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "missing = check[check[\"_merge\"] == \"left_only\"]\n",
    "print(missing[[\"menu\", \"order_id\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1bbbe4",
   "metadata": {},
   "source": [
    "indicator의 의미\n",
    "- both → 양쪽에 있음\n",
    "- left_only → 왼쪽에만 있음 (매핑 누락)\n",
    "- right_only → 오른쪽에만 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12910a1e",
   "metadata": {},
   "source": [
    "# 7. apply vs map 이론\n",
    "- map → 한 컬럼 값들을 딕셔너리로 치환할 때\n",
    "\n",
    "- apply → 규칙이 필요하거나 여러 컬럼을 같이 판단해야 할 때"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ebd5d8",
   "metadata": {},
   "source": [
    "## 7.1) map — “값 치환 / 매핑”에 특화\n",
    "map은 한 컬럼의 값들을 1:1로 바꿀 때 가장 적합하다.<br>\n",
    "즉, \"이 값이면 저 값으로 바꿔라\"가 명확헌 경우 map을 쓴다.\n",
    "\n",
    "<br>\n",
    "\n",
    "``` python\n",
    "Series.map(매핑_딕셔너리)\n",
    "```\n",
    "- 대상은 항상 단일 컬럼(Series)\n",
    "- 기준은 딕셔너리의 key → value\n",
    "\n",
    "어디에 사용하나?\n",
    "- 코드 → 이름 치환\n",
    "- 숫자 코드 → 등급명\n",
    "- 간단한 메뉴 / 카테고리 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33893edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매핑 전\n",
      "  channel\n",
      "0   kiosk\n",
      "1     app\n",
      "2   kiosk\n",
      "3     web\n",
      "\n",
      "  매핑 후\n",
      "  channel channel_name\n",
      "0   kiosk         키오스크\n",
      "1     app            앱\n",
      "2   kiosk         키오스크\n",
      "3     web            웹\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"channel\": [\"kiosk\", \"app\", \"kiosk\", \"web\"]\n",
    "})\n",
    "\n",
    "channel_map = {\n",
    "    \"kiosk\": \"키오스크\",\n",
    "    \"app\": \"앱\",\n",
    "    \"web\": \"웹\"\n",
    "}\n",
    "print(\"매핑 전\")\n",
    "print(df)\n",
    "\n",
    "# channel 컬럼의 값들을 channel_map 기준으로 그대로 치환한다\n",
    "df[\"channel_name\"] = df[\"channel\"].map(channel_map)\n",
    "print(\"\\n  매핑 후\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90615a",
   "metadata": {},
   "source": [
    "### 자주하는 실수포인트\n",
    "- 매핑표에 없는 값은 NaN이 된다\n",
    "- 그래서 항상 누락을 한 번 확인하는 게 좋다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e000b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [channel, channel_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "missing = df[df[\"channel_name\"].isna()]\n",
    "print(missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfd55f5",
   "metadata": {},
   "source": [
    "## 7.2) apply — “규칙(로직)”이 필요할 때\n",
    "apply는 딕셔너리로 표현할 수 없는 규칙이 있을 때 쓴다.\n",
    "\n",
    "- 조건문이 필요하거나\n",
    "- 계산 로직이 있거나\n",
    "- 여러 컬럼을 동시에 봐야 할때\n",
    "\n",
    "apply가 필요하다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b720e",
   "metadata": {},
   "source": [
    "### 문장 구조 (단일 컬럼)\n",
    "```python\n",
    "Series.apply(함수)\n",
    "```\n",
    "- 한 값씩 함수에 넣어서 처리\n",
    "- 단일 컬럼 기준 로직"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "626abd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sales grade\n",
      "0      0     C\n",
      "1   3000     B\n",
      "2  12000     A\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"sales\": [0, 3000, 12000]})\n",
    "\n",
    "def grade_sales(x):\n",
    "    if x == 0:\n",
    "        return \"C\"\n",
    "    elif x < 10000:\n",
    "        return \"B\"\n",
    "    else:\n",
    "        return \"A\"\n",
    "\n",
    "df[\"grade\"] = df[\"sales\"].apply(grade_sales)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec7804",
   "metadata": {},
   "source": [
    "### 문장 구조 (행 단위)\n",
    "```python\n",
    "DataFrame.apply(함수, axis=1)\n",
    "```\n",
    "- 여러 컬럼을 동시에 보고 판단\n",
    "- axis=1은 “행 기준”이라는 뜻\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2d344dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sales   paid label\n",
      "0  12000   True     A\n",
      "1   5000   True     B\n",
      "2   8000  False  FAIL\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"sales\": 12000, \"paid\": True},\n",
    "    {\"sales\": 5000,  \"paid\": True},\n",
    "    {\"sales\": 8000,  \"paid\": False},\n",
    "])\n",
    "\n",
    "def final_label(row):\n",
    "    if row[\"paid\"] is False:\n",
    "        return \"FAIL\"\n",
    "    if row[\"sales\"] >= 10000:\n",
    "        return \"A\"\n",
    "    return \"B\"\n",
    "\n",
    "df[\"label\"] = df.apply(final_label, axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bb59f",
   "metadata": {},
   "source": [
    "## 7.3) apply 사용시 주의사항\n",
    "apply는 보통 파이썬 함수가 행마다 실행되기 때문에 느리다.<br>\n",
    "그래서 데이터가 커지면 속도가 급격히 느려질 수 있다.<br>\n",
    "같은 로직이라도 조건식으로 한 번에 처리하면 훨씬 빠르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b36c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sales grade_vec\n",
      "0      0         C\n",
      "1   3000         B\n",
      "2  12000         A\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"sales\": [0, 3000, 12000]})\n",
    "\n",
    "df[\"grade_vec\"] = \"B\"\n",
    "df.loc[df[\"sales\"] == 0, \"grade_vec\"] = \"C\"\n",
    "df.loc[df[\"sales\"] >= 10000, \"grade_vec\"] = \"A\"\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3469bcf",
   "metadata": {},
   "source": [
    "# 8. 오늘 수업 정리\n",
    "\n",
    "\"원본 로그를 문자열/날짜 정리로 계산 가능하게 만들고, GroupBy로 요약하고, Merge로 정보 확장해서, 리포트용 표(요약테이블)를 만든다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3291a3",
   "metadata": {},
   "source": [
    "# 9. 초보자용 퀴즈(이론 체크, 5문항)\n",
    "1. GroupBy는 왜 필요한가? \"원본 로그\"와 비교해서 설명해보세요.\n",
    "2. paid_rate = mean(paid)가 \"비율\"이 되는 이유는?\n",
    "3. MultiIndex가 불편한 이유와 해결 방법 1가지는?\n",
    "4. merge의 left와 inner의 차이를 “매핑 누락 찾기” 관점에서 설명해보세요.\n",
    "5. map과 apply는 언제 각각 쓰는가? 예시 1개씩 들어보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facbe50d",
   "metadata": {},
   "source": [
    "## 정답\n",
    "1. 원본 로그는 거래 단위 데이터기 때문에 그대로는 요약이 안 된다.<br>GroupBy는 같은 기준(메뉴, 날짜 등)으로 묶어서 합계·평균 같은 리포트용 집계를 만들기 위해 필요하다.\n",
    "\n",
    "2. paid가 True/False일 때, True=1, False=0으로 계산된다.<br>그래서 평균은 전체 중 True의 비율이 된다.\n",
    "\n",
    "3. 컬럼/인덱스 접근이 복잡해지고 후처리가 귀찮아진다.<br>reset_index()로 평평한 형태로 바꾸는 게 가장 간단한 해결책이다.\n",
    "\n",
    "4. left는 원본을 전부 남겨서 매핑 누락이 NaN으로 드러난다.<br>inner는 매핑 안 된 행이 사라져서 누락을 찾기 어렵다.\n",
    "\n",
    "5. map은 값 치환처럼 1:1 매핑일 때 쓴다.<br>apply는 조건이나 규칙이 필요할 때 쓴다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f8bd3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
